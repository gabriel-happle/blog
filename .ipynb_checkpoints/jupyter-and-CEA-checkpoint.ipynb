{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with importing the necessary python libraries that we are going to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# import cea-specific libraries\n",
    "import cea.api # this is the API to call scripts in CEA, such as the data-helper, radiation engine, demand,...\n",
    "import cea.inputlocator # this module provides paths to input and output files according to the CEA folder structure\n",
    "import cea.config # this module let's us interact with the CEA configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we are going to set up our configuration to the desired case study. I am going to use the \"reference-case-cooling\" that ships with the CEA source code. Because CEA provides a script to extract the different reference cases, we can call this script via the API directly in jupyter notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the path to the destination folder\n",
    "path_to_folder_for_blog = os.path.expandvars(r'${userprofile}/Documents/GitHub/blog')\n",
    "# extract the reference-case-cooling to the destination folder\n",
    "cea.api.extract_reference_case(destination=path_to_folder_for_blog, case='cooling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I have extracted my case study, I have to make sure that the configuration for the other scripts points to the right folder. Therefore I am setting the project path and scenario name to the correct values. Setting the configuration can be done by manipulating the cea.config file with a text editor or also directly in jupyter via the `config.Configuration` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_project = os.path.join(path_to_folder_for_blog, 'reference-case-cooling') # construct the path to the project\n",
    "\n",
    "config = cea.config.Configuration() # load the configuration\n",
    "config.project = path_to_project # set the path to the project\n",
    "config.scenario_name = 'baseline' # set the scenario name\n",
    "print(config.scenario) # print the scenario to check the changes\n",
    "config.save() # save the changes to the cea.config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready for a run-through of the usual simulation steps for the district energy demand. They are:\n",
    "- Running the data-helper to set up our building model parameters\n",
    "- Running the radiation engine to quantify the solar heat gains of the buildings\n",
    "- Running the energy demand simulation\n",
    "\n",
    "The input into all scripts called via the CEA API is the configuration object. On my laptop it took around 10 minutes to run the scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cea.api.data_helper(region='SG') # run the data-helper script\n",
    "cea.api.radiation_daysim(weather='Singapore') # run the radiation engine\n",
    "cea.api.demand(weather='Singapore') # run the building energy demand simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use some python functionalities to create a new scenario by copying the files of the baseline scenario, modify some building occupancy schedules, and comparing the simulated energy demand results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scenario_name = 'modified-occupancy-schedules' # the new scenario name\n",
    "path_to_new_scenario = os.path.join(path_to_project, new_scenario_name) # create the destination path for copying the baseline scenario\n",
    "\n",
    "path_to_baseline = os.path.join(path_to_project, 'baseline')\n",
    "\n",
    "shutil.copytree(path_to_baseline, path_to_new_scenario) # copy the all files from the baseline to the new scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the CEA building-properties inputs are the various schedules that determine the occupant presence, ventilation rate, electrical appliance use, etc.\n",
    "These schedules are created based on the region-specific archetypes database during a demand simulation and saved to a CSV file, if they are not provided by the user. \n",
    "\n",
    "With the help of the CEA `inputlocator` we are going to read these building schedule files (they have been created during the baseline simulation and copied with the above code) and visualize them.\n",
    "\n",
    "The various colums contain information about:\n",
    "\n",
    "- `Ea` : Electrical appliance use\n",
    "- `Ed` : Electrical energy demand of data centers\n",
    "- `El` : Electrical lighting use\n",
    "- `Epro` : Electrical process energy use\n",
    "- `Qhpro` : Thermal process energy use\n",
    "- `Qs` : Sensible heat gains from occupants\n",
    "- `Vw` : Fresh water use\n",
    "- `Vww` : Hot water use\n",
    "- `X` : Latent heat gains (humidity gains) from occupants\n",
    "- `people` : Occupant presence\n",
    "- `ve` : Required ventilation rate due to occupant presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputlocator = cea.inputlocator.InputLocator(scenario=path_to_new_scenario) # the input for the inputlocator is the path to the scenario\n",
    "buildings = inputlocator.get_zone_building_names() # get all building names in scenario\n",
    "\n",
    "building_schedule_path = inputlocator.get_building_schedules(buildings[0]) # the path to the first building schedules file\n",
    "df_schedules = pd.read_csv(building_schedule_path) # use pandas to read the CSV file into a DataFrame\n",
    "\n",
    "df_schedules # print the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly visualize the data by plotting the first week of some schedules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules['Ea'][0:168].plot() # visualize 1 week of electrical appliance schedule\n",
    "plt.legend()\n",
    "plt.show()\n",
    "df_schedules['people'][0:168].plot() # visualize 1 week of occupant presence schedule\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I am going to introduce some randomness (or stochasticity) to the schedules by multiplying each value with a factor sampled from a normal distribution centered around 1 (`mu = 1`) with a standard distribution of 5% (`sigma = 0.05`).\n",
    "\n",
    "Such random factors can be obtaind with `sigma * np.random.randn(...) + mu`\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randn.html\n",
    "\n",
    "We can test and visualize how this looks like for our schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1.0\n",
    "sigma = 0.05\n",
    "\n",
    "df_schedules['Ea'][0:168].plot(label='default') # visualize 1 week of electrical appliance schedule\n",
    "df_schedules['Ea'] = df_schedules['Ea'] * (sigma * np.random.randn(8760) + mu) # randomize the schedule\n",
    "df_schedules['Ea'][0:168].plot(label='randomized')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df_schedules['people'][0:168].plot(label='default') # visualize 1 week of occupant presence schedule\n",
    "df_schedules['people'] = df_schedules['people'] * (sigma * np.random.randn(8760) + mu) # randomize the schedule\n",
    "df_schedules['people'][0:168].plot(label='randomized')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am simply going to randomize all schedules of all buildings in a nested `for` loop by reading, modifying and saving, the schedules again.\n",
    "When I save the schedules from DataFrames back to CSV I set `index=False` to comply with the default file format. However, the files should also work fine with CEA if they have some additional columns, such as an index. They will just be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = inputlocator.get_zone_building_names() # get all building names in scenario\n",
    "\n",
    "for building in buildings:\n",
    "    \n",
    "    building_schedule_path = inputlocator.get_building_schedules(building) # the path to the building schedules file\n",
    "    df_schedules = pd.read_csv(building_schedule_path) # use pandas to read the CSV file into a DataFrame\n",
    "    \n",
    "    for schedule in df_schedules.keys(): # iterate over all columns\n",
    "        \n",
    "        df_schedules[schedule] = df_schedules[schedule] * (sigma * np.random.randn(8760) + mu) # randomize the schedule\n",
    "\n",
    "    df_schedules.to_csv(building_schedule_path, index=False) # save the schedules after modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we do not want to change other building properties and because the schedules do not have an impact on the solar heat gains, I can now already run the energy demand simulation for my modified case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cea.api.demand(scenario=path_to_new_scenario, weather='Singapore') # run the demand simulation of the new scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the district energy demand results of our two case studies.\n",
    "For this simple example, I'm just going to look at the `Total_demand.csv` file that compiles a bunch of data for the district from the individual building demand output files.\n",
    "\n",
    "An interesting analysis would e.g., be to look at the differences in cumulative annual energy demands and peak power demands. We do not expect to see differences in annual energy demand, because the stochasticity factor introduced is normally distributed around 1 and deviations towards higher and lower energy consumption should balance out. However, we do expect to see some deviations in peak loads, but how much?\n",
    "\n",
    "The columns I'm going to look at are:\n",
    "\n",
    "- `QC_sys_MWhyr` the total annual cooling demand\n",
    "- `QC_sys0_kW` the peak cooling demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the new total demand file\n",
    "inputlocator_new = cea.inputlocator.InputLocator(scenario=path_to_new_scenario)\n",
    "total_demand_path_random = inputlocator_new.get_total_demand()\n",
    "df_total_demand_random = pd.read_csv(total_demand_path_random, index_col='Name')\n",
    "\n",
    "# get the baseline total demand file\n",
    "inputlocator_baseline = cea.inputlocator.InputLocator(scenario=path_to_baseline)\n",
    "total_demand_path_baseline = inputlocator_baseline.get_total_demand()\n",
    "df_total_demand_baseline = pd.read_csv(total_demand_path_baseline, index_col='Name')\n",
    "\n",
    "# plot the yearly cooling energy demand\n",
    "fig, ax = plt.subplots()\n",
    "x_data = np.arange(len(df_total_demand_baseline.index))\n",
    "ax.bar(x_data-0.1, df_total_demand_baseline['QC_sys_MWhyr'], width=0.6, label='baseline')\n",
    "ax.bar(x_data+0.1, df_total_demand_random['QC_sys_MWhyr'], width=0.6, label='randomized schedule')\n",
    "ax.set_xticks(x_data)\n",
    "ax.set_xticklabels(df_total_demand_baseline.index)\n",
    "plt.ylabel('yearly cooling energy use (MWh/yr)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the peak cooling energy demand\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x_data-0.1, df_total_demand_baseline['QC_sys0_kW'], width=0.6, label='baseline')\n",
    "ax.bar(x_data+0.1, df_total_demand_random['QC_sys0_kW'], width=0.6, label='randomized schedule')\n",
    "ax.set_xticks(x_data)\n",
    "ax.set_xticklabels(df_total_demand_baseline.index)\n",
    "plt.ylabel('peak cooling demand (kW)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the buildings' peak cooling loads are affected in different ways...\n",
    "There seem to be lot's of research opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
